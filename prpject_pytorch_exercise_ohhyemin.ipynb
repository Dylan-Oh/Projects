{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : PyTorch 실습\n",
    "### 제출일 : 2023.05.30\n",
    "### 성명 및 학번 : 오혜민(2023254013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n!pip install torchtext==0.11.0\\n!pip install --upgrade torch torchvision\\n\\nimport numpy as np\\nimport torch\\nfrom torch.autograd import Variable\\nimport torchvision\\nimport torchtext\\n\\nprint(f'torch version: {torch.__version__}')\\nprint(f'torchvision version: {torchvision.__version__}')\\nprint(f'torchtext version: {torchtext.__version__}')\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install torchtext==0.11.0\n",
    "!pip install --upgrade torch torchvision\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchtext\n",
    "\n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'torchvision version: {torchvision.__version__}')\n",
    "print(f'torchtext version: {torchtext.__version__}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Colab에서 PyTorch 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "\n",
    "X = mnist.data/255\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 레이블 : 5\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[36000]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "'''\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "\n",
    "'''\n",
    "plt.imshow(X[0].reshape(28,28), cmap='gray')\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(\"이미지 레이블 : {}\".format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch의 MLP 프로그래밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "\n",
    "X = mnist.data/255\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 레이블 : 5\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].reshape(28,28), cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(\"이미지 레이블 : {}\".format(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=1/7, random_state=0) \n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(list(map(int, y_train)))\n",
    "y_test = torch.LongTensor(list(map(int, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(28*28*1, 100)) #모델 구성\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2', nn.Linear(100,100))\n",
    "model.add_module('relu2', nn.ReLU()) \n",
    "model.add_module('fc3', nn.Linear(100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim \n",
    "loss_fn = nn.CrossEntropyLoss() #손실 함수\n",
    "optimizer = optim.Adam(model.parameters( ), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 정확도: 1079/10000(10.79%)\n",
      "에포크 0: 완료\n",
      "학습중 정확도: 9470/10000(94.70%)\n",
      "에포크 1: 완료\n",
      "학습중 정확도: 9598/10000(95.98%)\n",
      "에포크 2: 완료\n",
      "학습중 정확도: 9595/10000(95.95%)\n",
      "학습 후 정확도: 9595/10000(95.95%)\n",
      "10번째 학습데이터의 테스트 결과 : tensor([ 2.0844, 11.1080, -8.6455, -5.7945, -5.2159, -4.3143, -8.6585,  0.2686,\n",
      "         2.5298,  0.1157], grad_fn=<AddBackward0>)\n",
      "10번째 학습데이터의 테스트 예측 : 1\n",
      "실제 레이블:1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train() #학습 모드로 변환\n",
    "    for data, targets in loader_train: \n",
    "        optimizer.zero_grad() #그레디언트 초기화\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, targets) #outputs를 output으로 수정함 2023.05.29\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    print('에포크 {}: 완료'.format(epoch))\n",
    "    \n",
    "def test(head):\n",
    "    model.eval() #테스트 모드로 변환\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader_test:\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum()\n",
    "    data_num = len(loader_test.dataset)\n",
    "    print('{} 정확도: {}/{}({:.2f}%)'.format(head, correct, data_num, 100.*correct/data_num)) # of를 2f로 수정함 2023.05.29\n",
    "\n",
    "test('시작')\n",
    "for epoch in range(3):\n",
    "    train(epoch)\n",
    "    test('학습중')\n",
    "test('학습 후')\n",
    "\n",
    "index = 10 #테스트 데이터 중에서 확인해볼 데이터의 인덱스\n",
    "model.eval() #모델 테스트 모드로 전환\n",
    "data = X_test[index]\n",
    "output = model(data) #모델 적용\n",
    "print('{}번째 학습데이터의 테스트 결과 : {}'.format(index,output))\n",
    "_, predicted = torch.max(output.data, 0)\n",
    "print('{}번째 학습데이터의 테스트 예측 : {}'.format(index,predicted))\n",
    "X_test_show = (X_test[index]).numpy()\n",
    "plt.imshow(X_test_show.reshape(28,28), cmap='gray')\n",
    "print('실제 레이블:{}'.format(y_test[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN 모델을 이용한 MNIST 데이터 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "X = mnist.data\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=0)\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train.astype(int))\n",
    "y_test = torch.LongTensor(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n",
      "torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.view(-1, 1, 28, 28).float()\n",
    "X_test = X_test.view(-1, 1, 28, 28).float()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(X_train, y_train)\n",
    "test = TensorDataset(X_test, y_test)\n",
    "BATCH_SIZE = 32\n",
    "loader_train = DataLoader(train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "loader_test = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntorch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\\n\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1, 3*3*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loader_train):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 10\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(loader_train):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            predicted = torch.max(output.data, 1)[1]\n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(loader_train.dataset),\n",
    "                    100.*batch_idx / len(loader_train), loss.data.item(), float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    correct = 0\n",
    "    for test_imgs, test_labels in loader_test:\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output, 1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(loader_test)*BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.101% \n",
      "Epoch : 0 [0/60000 (0%)]\tLoss: 19.909086\t Accuracy:9.375%\n",
      "Epoch : 0 [1600/60000 (3%)]\tLoss: 2.058422\t Accuracy:15.012%\n",
      "Epoch : 0 [3200/60000 (5%)]\tLoss: 1.537113\t Accuracy:29.981%\n",
      "Epoch : 0 [4800/60000 (8%)]\tLoss: 0.997362\t Accuracy:41.494%\n",
      "Epoch : 0 [6400/60000 (11%)]\tLoss: 0.577645\t Accuracy:48.881%\n",
      "Epoch : 0 [8000/60000 (13%)]\tLoss: 1.017035\t Accuracy:55.242%\n",
      "Epoch : 0 [9600/60000 (16%)]\tLoss: 0.732274\t Accuracy:60.008%\n",
      "Epoch : 0 [11200/60000 (19%)]\tLoss: 0.762013\t Accuracy:63.791%\n",
      "Epoch : 0 [12800/60000 (21%)]\tLoss: 0.634818\t Accuracy:66.716%\n",
      "Epoch : 0 [14400/60000 (24%)]\tLoss: 0.671219\t Accuracy:68.902%\n",
      "Epoch : 0 [16000/60000 (27%)]\tLoss: 0.181993\t Accuracy:70.877%\n",
      "Epoch : 0 [17600/60000 (29%)]\tLoss: 0.350297\t Accuracy:72.351%\n",
      "Epoch : 0 [19200/60000 (32%)]\tLoss: 0.379039\t Accuracy:73.799%\n",
      "Epoch : 0 [20800/60000 (35%)]\tLoss: 0.187426\t Accuracy:75.086%\n",
      "Epoch : 0 [22400/60000 (37%)]\tLoss: 0.240783\t Accuracy:76.221%\n",
      "Epoch : 0 [24000/60000 (40%)]\tLoss: 0.292873\t Accuracy:77.226%\n",
      "Epoch : 0 [25600/60000 (43%)]\tLoss: 0.238533\t Accuracy:78.133%\n",
      "Epoch : 0 [27200/60000 (45%)]\tLoss: 0.763556\t Accuracy:78.944%\n",
      "Epoch : 0 [28800/60000 (48%)]\tLoss: 0.426360\t Accuracy:79.665%\n",
      "Epoch : 0 [30400/60000 (51%)]\tLoss: 0.106152\t Accuracy:80.366%\n",
      "Epoch : 0 [32000/60000 (53%)]\tLoss: 0.331757\t Accuracy:80.925%\n",
      "Epoch : 0 [33600/60000 (56%)]\tLoss: 0.261223\t Accuracy:81.470%\n",
      "Epoch : 0 [35200/60000 (59%)]\tLoss: 0.064339\t Accuracy:81.971%\n",
      "Epoch : 0 [36800/60000 (61%)]\tLoss: 0.120090\t Accuracy:82.415%\n",
      "Epoch : 0 [38400/60000 (64%)]\tLoss: 0.234547\t Accuracy:82.894%\n",
      "Epoch : 0 [40000/60000 (67%)]\tLoss: 0.216881\t Accuracy:83.341%\n",
      "Epoch : 0 [41600/60000 (69%)]\tLoss: 0.445226\t Accuracy:83.700%\n",
      "Epoch : 0 [43200/60000 (72%)]\tLoss: 0.125743\t Accuracy:84.026%\n",
      "Epoch : 0 [44800/60000 (75%)]\tLoss: 0.143464\t Accuracy:84.357%\n",
      "Epoch : 0 [46400/60000 (77%)]\tLoss: 0.115196\t Accuracy:84.687%\n",
      "Epoch : 0 [48000/60000 (80%)]\tLoss: 0.508319\t Accuracy:84.977%\n",
      "Epoch : 0 [49600/60000 (83%)]\tLoss: 0.334091\t Accuracy:85.213%\n",
      "Epoch : 0 [51200/60000 (85%)]\tLoss: 0.196123\t Accuracy:85.476%\n",
      "Epoch : 0 [52800/60000 (88%)]\tLoss: 0.233244\t Accuracy:85.719%\n",
      "Epoch : 0 [54400/60000 (91%)]\tLoss: 0.428404\t Accuracy:85.986%\n",
      "Epoch : 0 [56000/60000 (93%)]\tLoss: 0.290295\t Accuracy:86.206%\n",
      "Epoch : 0 [57600/60000 (96%)]\tLoss: 0.068764\t Accuracy:86.461%\n",
      "Epoch : 0 [59200/60000 (99%)]\tLoss: 0.137651\t Accuracy:86.690%\n",
      "Epoch : 1 [0/60000 (0%)]\tLoss: 0.153315\t Accuracy:90.625%\n",
      "Epoch : 1 [1600/60000 (3%)]\tLoss: 0.065176\t Accuracy:93.505%\n",
      "Epoch : 1 [3200/60000 (5%)]\tLoss: 0.564112\t Accuracy:93.874%\n",
      "Epoch : 1 [4800/60000 (8%)]\tLoss: 0.128100\t Accuracy:93.771%\n",
      "Epoch : 1 [6400/60000 (11%)]\tLoss: 0.361692\t Accuracy:93.843%\n",
      "Epoch : 1 [8000/60000 (13%)]\tLoss: 0.491422\t Accuracy:94.186%\n",
      "Epoch : 1 [9600/60000 (16%)]\tLoss: 0.143066\t Accuracy:94.176%\n",
      "Epoch : 1 [11200/60000 (19%)]\tLoss: 0.301647\t Accuracy:94.302%\n",
      "Epoch : 1 [12800/60000 (21%)]\tLoss: 0.399980\t Accuracy:94.397%\n",
      "Epoch : 1 [14400/60000 (24%)]\tLoss: 0.075221\t Accuracy:94.471%\n",
      "Epoch : 1 [16000/60000 (27%)]\tLoss: 0.029477\t Accuracy:94.405%\n",
      "Epoch : 1 [17600/60000 (29%)]\tLoss: 0.134271\t Accuracy:94.317%\n",
      "Epoch : 1 [19200/60000 (32%)]\tLoss: 0.395517\t Accuracy:94.286%\n",
      "Epoch : 1 [20800/60000 (35%)]\tLoss: 0.277315\t Accuracy:94.312%\n",
      "Epoch : 1 [22400/60000 (37%)]\tLoss: 0.143800\t Accuracy:94.312%\n",
      "Epoch : 1 [24000/60000 (40%)]\tLoss: 0.144210\t Accuracy:94.320%\n",
      "Epoch : 1 [25600/60000 (43%)]\tLoss: 0.360365\t Accuracy:94.339%\n",
      "Epoch : 1 [27200/60000 (45%)]\tLoss: 0.257993\t Accuracy:94.316%\n",
      "Epoch : 1 [28800/60000 (48%)]\tLoss: 0.265912\t Accuracy:94.315%\n",
      "Epoch : 1 [30400/60000 (51%)]\tLoss: 0.120312\t Accuracy:94.348%\n",
      "Epoch : 1 [32000/60000 (53%)]\tLoss: 0.128346\t Accuracy:94.349%\n",
      "Epoch : 1 [33600/60000 (56%)]\tLoss: 0.175748\t Accuracy:94.425%\n",
      "Epoch : 1 [35200/60000 (59%)]\tLoss: 0.027437\t Accuracy:94.462%\n",
      "Epoch : 1 [36800/60000 (61%)]\tLoss: 0.216775\t Accuracy:94.469%\n",
      "Epoch : 1 [38400/60000 (64%)]\tLoss: 0.141654\t Accuracy:94.481%\n",
      "Epoch : 1 [40000/60000 (67%)]\tLoss: 0.087642\t Accuracy:94.524%\n",
      "Epoch : 1 [41600/60000 (69%)]\tLoss: 0.452775\t Accuracy:94.478%\n",
      "Epoch : 1 [43200/60000 (72%)]\tLoss: 0.055440\t Accuracy:94.442%\n",
      "Epoch : 1 [44800/60000 (75%)]\tLoss: 0.140144\t Accuracy:94.459%\n",
      "Epoch : 1 [46400/60000 (77%)]\tLoss: 0.210578\t Accuracy:94.446%\n",
      "Epoch : 1 [48000/60000 (80%)]\tLoss: 0.190335\t Accuracy:94.468%\n",
      "Epoch : 1 [49600/60000 (83%)]\tLoss: 0.188158\t Accuracy:94.471%\n",
      "Epoch : 1 [51200/60000 (85%)]\tLoss: 0.033903\t Accuracy:94.496%\n",
      "Epoch : 1 [52800/60000 (88%)]\tLoss: 0.121650\t Accuracy:94.473%\n",
      "Epoch : 1 [54400/60000 (91%)]\tLoss: 0.202623\t Accuracy:94.498%\n",
      "Epoch : 1 [56000/60000 (93%)]\tLoss: 0.290977\t Accuracy:94.526%\n",
      "Epoch : 1 [57600/60000 (96%)]\tLoss: 0.281789\t Accuracy:94.534%\n",
      "Epoch : 1 [59200/60000 (99%)]\tLoss: 0.035718\t Accuracy:94.550%\n",
      "Epoch : 2 [0/60000 (0%)]\tLoss: 0.186329\t Accuracy:93.750%\n",
      "Epoch : 2 [1600/60000 (3%)]\tLoss: 0.071692\t Accuracy:92.218%\n",
      "Epoch : 2 [3200/60000 (5%)]\tLoss: 0.228698\t Accuracy:93.719%\n",
      "Epoch : 2 [4800/60000 (8%)]\tLoss: 0.263172\t Accuracy:94.516%\n",
      "Epoch : 2 [6400/60000 (11%)]\tLoss: 0.118876\t Accuracy:94.652%\n",
      "Epoch : 2 [8000/60000 (13%)]\tLoss: 0.275146\t Accuracy:94.609%\n",
      "Epoch : 2 [9600/60000 (16%)]\tLoss: 0.004530\t Accuracy:94.819%\n",
      "Epoch : 2 [11200/60000 (19%)]\tLoss: 0.094058\t Accuracy:95.005%\n",
      "Epoch : 2 [12800/60000 (21%)]\tLoss: 0.541561\t Accuracy:95.145%\n",
      "Epoch : 2 [14400/60000 (24%)]\tLoss: 0.262719\t Accuracy:94.983%\n",
      "Epoch : 2 [16000/60000 (27%)]\tLoss: 0.019757\t Accuracy:94.979%\n",
      "Epoch : 2 [17600/60000 (29%)]\tLoss: 0.072212\t Accuracy:94.913%\n",
      "Epoch : 2 [19200/60000 (32%)]\tLoss: 0.376011\t Accuracy:94.894%\n",
      "Epoch : 2 [20800/60000 (35%)]\tLoss: 0.121961\t Accuracy:94.868%\n",
      "Epoch : 2 [22400/60000 (37%)]\tLoss: 0.139162\t Accuracy:94.909%\n",
      "Epoch : 2 [24000/60000 (40%)]\tLoss: 0.247403\t Accuracy:94.903%\n",
      "Epoch : 2 [25600/60000 (43%)]\tLoss: 0.167876\t Accuracy:94.975%\n",
      "Epoch : 2 [27200/60000 (45%)]\tLoss: 0.268158\t Accuracy:95.006%\n",
      "Epoch : 2 [28800/60000 (48%)]\tLoss: 0.309598\t Accuracy:94.985%\n",
      "Epoch : 2 [30400/60000 (51%)]\tLoss: 0.020353\t Accuracy:94.999%\n",
      "Epoch : 2 [32000/60000 (53%)]\tLoss: 0.144524\t Accuracy:95.033%\n",
      "Epoch : 2 [33600/60000 (56%)]\tLoss: 0.069026\t Accuracy:95.011%\n",
      "Epoch : 2 [35200/60000 (59%)]\tLoss: 0.021921\t Accuracy:95.027%\n",
      "Epoch : 2 [36800/60000 (61%)]\tLoss: 0.030815\t Accuracy:95.050%\n",
      "Epoch : 2 [38400/60000 (64%)]\tLoss: 0.052705\t Accuracy:95.082%\n",
      "Epoch : 2 [40000/60000 (67%)]\tLoss: 0.130041\t Accuracy:95.114%\n",
      "Epoch : 2 [41600/60000 (69%)]\tLoss: 0.219334\t Accuracy:95.141%\n",
      "Epoch : 2 [43200/60000 (72%)]\tLoss: 0.065167\t Accuracy:95.161%\n",
      "Epoch : 2 [44800/60000 (75%)]\tLoss: 0.091152\t Accuracy:95.126%\n",
      "Epoch : 2 [46400/60000 (77%)]\tLoss: 0.034307\t Accuracy:95.163%\n",
      "Epoch : 2 [48000/60000 (80%)]\tLoss: 0.613674\t Accuracy:95.166%\n",
      "Epoch : 2 [49600/60000 (83%)]\tLoss: 0.347499\t Accuracy:95.183%\n",
      "Epoch : 2 [51200/60000 (85%)]\tLoss: 0.099129\t Accuracy:95.187%\n",
      "Epoch : 2 [52800/60000 (88%)]\tLoss: 0.148557\t Accuracy:95.130%\n",
      "Epoch : 2 [54400/60000 (91%)]\tLoss: 0.057351\t Accuracy:95.143%\n",
      "Epoch : 2 [56000/60000 (93%)]\tLoss: 0.156553\t Accuracy:95.138%\n",
      "Epoch : 2 [57600/60000 (96%)]\tLoss: 0.072758\t Accuracy:95.168%\n",
      "Epoch : 2 [59200/60000 (99%)]\tLoss: 0.051501\t Accuracy:95.212%\n",
      "Epoch : 3 [0/60000 (0%)]\tLoss: 0.066026\t Accuracy:96.875%\n",
      "Epoch : 3 [1600/60000 (3%)]\tLoss: 0.045412\t Accuracy:94.179%\n",
      "Epoch : 3 [3200/60000 (5%)]\tLoss: 0.251394\t Accuracy:94.802%\n",
      "Epoch : 3 [4800/60000 (8%)]\tLoss: 0.308688\t Accuracy:94.950%\n",
      "Epoch : 3 [6400/60000 (11%)]\tLoss: 0.207692\t Accuracy:95.103%\n",
      "Epoch : 3 [8000/60000 (13%)]\tLoss: 0.364321\t Accuracy:95.294%\n",
      "Epoch : 3 [9600/60000 (16%)]\tLoss: 0.046808\t Accuracy:95.546%\n",
      "Epoch : 3 [11200/60000 (19%)]\tLoss: 0.096244\t Accuracy:95.620%\n",
      "Epoch : 3 [12800/60000 (21%)]\tLoss: 0.347724\t Accuracy:95.503%\n",
      "Epoch : 3 [14400/60000 (24%)]\tLoss: 0.016795\t Accuracy:95.531%\n",
      "Epoch : 3 [16000/60000 (27%)]\tLoss: 0.007347\t Accuracy:95.565%\n",
      "Epoch : 3 [17600/60000 (29%)]\tLoss: 0.267138\t Accuracy:95.451%\n",
      "Epoch : 3 [19200/60000 (32%)]\tLoss: 0.221369\t Accuracy:95.450%\n",
      "Epoch : 3 [20800/60000 (35%)]\tLoss: 0.138920\t Accuracy:95.454%\n",
      "Epoch : 3 [22400/60000 (37%)]\tLoss: 0.169618\t Accuracy:95.466%\n",
      "Epoch : 3 [24000/60000 (40%)]\tLoss: 0.089127\t Accuracy:95.469%\n",
      "Epoch : 3 [25600/60000 (43%)]\tLoss: 0.048504\t Accuracy:95.552%\n",
      "Epoch : 3 [27200/60000 (45%)]\tLoss: 0.475933\t Accuracy:95.586%\n",
      "Epoch : 3 [28800/60000 (48%)]\tLoss: 0.212230\t Accuracy:95.564%\n",
      "Epoch : 3 [30400/60000 (51%)]\tLoss: 0.136004\t Accuracy:95.567%\n",
      "Epoch : 3 [32000/60000 (53%)]\tLoss: 0.076770\t Accuracy:95.570%\n",
      "Epoch : 3 [33600/60000 (56%)]\tLoss: 0.489939\t Accuracy:95.588%\n",
      "Epoch : 3 [35200/60000 (59%)]\tLoss: 0.021689\t Accuracy:95.589%\n",
      "Epoch : 3 [36800/60000 (61%)]\tLoss: 0.243371\t Accuracy:95.613%\n",
      "Epoch : 3 [38400/60000 (64%)]\tLoss: 0.177169\t Accuracy:95.631%\n",
      "Epoch : 3 [40000/60000 (67%)]\tLoss: 0.160317\t Accuracy:95.673%\n",
      "Epoch : 3 [41600/60000 (69%)]\tLoss: 0.331572\t Accuracy:95.681%\n",
      "Epoch : 3 [43200/60000 (72%)]\tLoss: 0.089892\t Accuracy:95.698%\n",
      "Epoch : 3 [44800/60000 (75%)]\tLoss: 0.171959\t Accuracy:95.693%\n",
      "Epoch : 3 [46400/60000 (77%)]\tLoss: 0.138793\t Accuracy:95.695%\n",
      "Epoch : 3 [48000/60000 (80%)]\tLoss: 0.738934\t Accuracy:95.690%\n",
      "Epoch : 3 [49600/60000 (83%)]\tLoss: 0.113713\t Accuracy:95.706%\n",
      "Epoch : 3 [51200/60000 (85%)]\tLoss: 0.151518\t Accuracy:95.719%\n",
      "Epoch : 3 [52800/60000 (88%)]\tLoss: 0.448868\t Accuracy:95.724%\n",
      "Epoch : 3 [54400/60000 (91%)]\tLoss: 0.068231\t Accuracy:95.721%\n",
      "Epoch : 3 [56000/60000 (93%)]\tLoss: 0.011913\t Accuracy:95.742%\n",
      "Epoch : 3 [57600/60000 (96%)]\tLoss: 0.008483\t Accuracy:95.761%\n",
      "Epoch : 3 [59200/60000 (99%)]\tLoss: 0.495487\t Accuracy:95.757%\n",
      "Epoch : 4 [0/60000 (0%)]\tLoss: 0.022257\t Accuracy:100.000%\n",
      "Epoch : 4 [1600/60000 (3%)]\tLoss: 0.069163\t Accuracy:94.853%\n",
      "Epoch : 4 [3200/60000 (5%)]\tLoss: 0.104160\t Accuracy:95.019%\n",
      "Epoch : 4 [4800/60000 (8%)]\tLoss: 0.257837\t Accuracy:95.344%\n",
      "Epoch : 4 [6400/60000 (11%)]\tLoss: 0.230268\t Accuracy:95.631%\n",
      "Epoch : 4 [8000/60000 (13%)]\tLoss: 0.338259\t Accuracy:95.742%\n",
      "Epoch : 4 [9600/60000 (16%)]\tLoss: 0.105100\t Accuracy:95.816%\n",
      "Epoch : 4 [11200/60000 (19%)]\tLoss: 0.036675\t Accuracy:95.878%\n",
      "Epoch : 4 [12800/60000 (21%)]\tLoss: 0.195445\t Accuracy:95.807%\n",
      "Epoch : 4 [14400/60000 (24%)]\tLoss: 0.131846\t Accuracy:95.642%\n",
      "Epoch : 4 [16000/60000 (27%)]\tLoss: 0.003965\t Accuracy:95.640%\n",
      "Epoch : 4 [17600/60000 (29%)]\tLoss: 0.013435\t Accuracy:95.520%\n",
      "Epoch : 4 [19200/60000 (32%)]\tLoss: 0.143282\t Accuracy:95.533%\n",
      "Epoch : 4 [20800/60000 (35%)]\tLoss: 0.013107\t Accuracy:95.555%\n",
      "Epoch : 4 [22400/60000 (37%)]\tLoss: 0.039653\t Accuracy:95.560%\n",
      "Epoch : 4 [24000/60000 (40%)]\tLoss: 0.169874\t Accuracy:95.606%\n",
      "Epoch : 4 [25600/60000 (43%)]\tLoss: 0.137189\t Accuracy:95.689%\n",
      "Epoch : 4 [27200/60000 (45%)]\tLoss: 0.042789\t Accuracy:95.689%\n",
      "Epoch : 4 [28800/60000 (48%)]\tLoss: 0.123452\t Accuracy:95.710%\n",
      "Epoch : 4 [30400/60000 (51%)]\tLoss: 0.099457\t Accuracy:95.715%\n",
      "Epoch : 4 [32000/60000 (53%)]\tLoss: 0.079975\t Accuracy:95.692%\n",
      "Epoch : 4 [33600/60000 (56%)]\tLoss: 0.210027\t Accuracy:95.653%\n",
      "Epoch : 4 [35200/60000 (59%)]\tLoss: 0.014649\t Accuracy:95.632%\n",
      "Epoch : 4 [36800/60000 (61%)]\tLoss: 0.271202\t Accuracy:95.626%\n",
      "Epoch : 4 [38400/60000 (64%)]\tLoss: 0.037273\t Accuracy:95.662%\n",
      "Epoch : 4 [40000/60000 (67%)]\tLoss: 0.141601\t Accuracy:95.681%\n",
      "Epoch : 4 [41600/60000 (69%)]\tLoss: 0.035783\t Accuracy:95.686%\n",
      "Epoch : 4 [43200/60000 (72%)]\tLoss: 0.087081\t Accuracy:95.675%\n",
      "Epoch : 4 [44800/60000 (75%)]\tLoss: 0.173009\t Accuracy:95.650%\n",
      "Epoch : 4 [46400/60000 (77%)]\tLoss: 0.073075\t Accuracy:95.669%\n",
      "Epoch : 4 [48000/60000 (80%)]\tLoss: 0.349395\t Accuracy:95.703%\n",
      "Epoch : 4 [49600/60000 (83%)]\tLoss: 0.214944\t Accuracy:95.721%\n",
      "Epoch : 4 [51200/60000 (85%)]\tLoss: 0.206912\t Accuracy:95.753%\n",
      "Epoch : 4 [52800/60000 (88%)]\tLoss: 0.094308\t Accuracy:95.736%\n",
      "Epoch : 4 [54400/60000 (91%)]\tLoss: 0.039346\t Accuracy:95.723%\n",
      "Epoch : 4 [56000/60000 (93%)]\tLoss: 0.119123\t Accuracy:95.727%\n",
      "Epoch : 4 [57600/60000 (96%)]\tLoss: 0.143750\t Accuracy:95.770%\n",
      "Epoch : 4 [59200/60000 (99%)]\tLoss: 0.047304\t Accuracy:95.800%\n",
      "Epoch : 5 [0/60000 (0%)]\tLoss: 0.117107\t Accuracy:93.750%\n",
      "Epoch : 5 [1600/60000 (3%)]\tLoss: 0.040233\t Accuracy:94.485%\n",
      "Epoch : 5 [3200/60000 (5%)]\tLoss: 0.616207\t Accuracy:95.235%\n",
      "Epoch : 5 [4800/60000 (8%)]\tLoss: 0.322557\t Accuracy:95.675%\n",
      "Epoch : 5 [6400/60000 (11%)]\tLoss: 0.027629\t Accuracy:95.802%\n",
      "Epoch : 5 [8000/60000 (13%)]\tLoss: 0.200994\t Accuracy:95.929%\n",
      "Epoch : 5 [9600/60000 (16%)]\tLoss: 0.018766\t Accuracy:95.982%\n",
      "Epoch : 5 [11200/60000 (19%)]\tLoss: 0.062414\t Accuracy:95.940%\n",
      "Epoch : 5 [12800/60000 (21%)]\tLoss: 0.405112\t Accuracy:95.901%\n",
      "Epoch : 5 [14400/60000 (24%)]\tLoss: 0.132310\t Accuracy:95.919%\n",
      "Epoch : 5 [16000/60000 (27%)]\tLoss: 0.031631\t Accuracy:95.939%\n",
      "Epoch : 5 [17600/60000 (29%)]\tLoss: 0.101707\t Accuracy:95.860%\n",
      "Epoch : 5 [19200/60000 (32%)]\tLoss: 0.089987\t Accuracy:95.840%\n",
      "Epoch : 5 [20800/60000 (35%)]\tLoss: 0.020057\t Accuracy:95.872%\n",
      "Epoch : 5 [22400/60000 (37%)]\tLoss: 0.010298\t Accuracy:95.912%\n",
      "Epoch : 5 [24000/60000 (40%)]\tLoss: 0.230267\t Accuracy:95.914%\n",
      "Epoch : 5 [25600/60000 (43%)]\tLoss: 0.042253\t Accuracy:95.958%\n",
      "Epoch : 5 [27200/60000 (45%)]\tLoss: 0.401735\t Accuracy:95.990%\n",
      "Epoch : 5 [28800/60000 (48%)]\tLoss: 0.054716\t Accuracy:95.907%\n",
      "Epoch : 5 [30400/60000 (51%)]\tLoss: 0.148066\t Accuracy:95.906%\n",
      "Epoch : 5 [32000/60000 (53%)]\tLoss: 0.024526\t Accuracy:95.920%\n",
      "Epoch : 5 [33600/60000 (56%)]\tLoss: 0.301225\t Accuracy:95.912%\n",
      "Epoch : 5 [35200/60000 (59%)]\tLoss: 0.038203\t Accuracy:95.933%\n",
      "Epoch : 5 [36800/60000 (61%)]\tLoss: 0.060897\t Accuracy:95.911%\n",
      "Epoch : 5 [38400/60000 (64%)]\tLoss: 0.142171\t Accuracy:95.917%\n",
      "Epoch : 5 [40000/60000 (67%)]\tLoss: 0.113393\t Accuracy:95.916%\n",
      "Epoch : 5 [41600/60000 (69%)]\tLoss: 0.093513\t Accuracy:95.929%\n",
      "Epoch : 5 [43200/60000 (72%)]\tLoss: 0.222450\t Accuracy:95.913%\n",
      "Epoch : 5 [44800/60000 (75%)]\tLoss: 0.018545\t Accuracy:95.900%\n",
      "Epoch : 5 [46400/60000 (77%)]\tLoss: 0.164599\t Accuracy:95.917%\n",
      "Epoch : 5 [48000/60000 (80%)]\tLoss: 0.514659\t Accuracy:95.926%\n",
      "Epoch : 5 [49600/60000 (83%)]\tLoss: 0.240707\t Accuracy:95.934%\n",
      "Epoch : 5 [51200/60000 (85%)]\tLoss: 0.100242\t Accuracy:95.950%\n",
      "Epoch : 5 [52800/60000 (88%)]\tLoss: 0.108005\t Accuracy:95.944%\n",
      "Epoch : 5 [54400/60000 (91%)]\tLoss: 0.068321\t Accuracy:95.956%\n",
      "Epoch : 5 [56000/60000 (93%)]\tLoss: 0.065132\t Accuracy:95.945%\n",
      "Epoch : 5 [57600/60000 (96%)]\tLoss: 0.091879\t Accuracy:95.964%\n",
      "Epoch : 5 [59200/60000 (99%)]\tLoss: 0.043334\t Accuracy:95.972%\n",
      "Epoch : 6 [0/60000 (0%)]\tLoss: 0.133015\t Accuracy:96.875%\n",
      "Epoch : 6 [1600/60000 (3%)]\tLoss: 0.175804\t Accuracy:95.343%\n",
      "Epoch : 6 [3200/60000 (5%)]\tLoss: 0.143050\t Accuracy:95.514%\n",
      "Epoch : 6 [4800/60000 (8%)]\tLoss: 0.318335\t Accuracy:95.840%\n",
      "Epoch : 6 [6400/60000 (11%)]\tLoss: 0.271446\t Accuracy:95.849%\n",
      "Epoch : 6 [8000/60000 (13%)]\tLoss: 0.220758\t Accuracy:95.966%\n",
      "Epoch : 6 [9600/60000 (16%)]\tLoss: 0.281639\t Accuracy:96.148%\n",
      "Epoch : 6 [11200/60000 (19%)]\tLoss: 0.869151\t Accuracy:96.136%\n",
      "Epoch : 6 [12800/60000 (21%)]\tLoss: 0.228583\t Accuracy:96.049%\n",
      "Epoch : 6 [14400/60000 (24%)]\tLoss: 0.129668\t Accuracy:96.064%\n",
      "Epoch : 6 [16000/60000 (27%)]\tLoss: 0.016819\t Accuracy:96.052%\n",
      "Epoch : 6 [17600/60000 (29%)]\tLoss: 0.256091\t Accuracy:96.047%\n",
      "Epoch : 6 [19200/60000 (32%)]\tLoss: 0.180331\t Accuracy:96.017%\n",
      "Epoch : 6 [20800/60000 (35%)]\tLoss: 0.015913\t Accuracy:95.992%\n",
      "Epoch : 6 [22400/60000 (37%)]\tLoss: 0.025418\t Accuracy:96.068%\n",
      "Epoch : 6 [24000/60000 (40%)]\tLoss: 0.166883\t Accuracy:96.064%\n",
      "Epoch : 6 [25600/60000 (43%)]\tLoss: 0.235272\t Accuracy:96.122%\n",
      "Epoch : 6 [27200/60000 (45%)]\tLoss: 0.338390\t Accuracy:96.115%\n",
      "Epoch : 6 [28800/60000 (48%)]\tLoss: 0.324320\t Accuracy:96.115%\n",
      "Epoch : 6 [30400/60000 (51%)]\tLoss: 0.095157\t Accuracy:96.123%\n",
      "Epoch : 6 [32000/60000 (53%)]\tLoss: 0.178765\t Accuracy:96.126%\n",
      "Epoch : 6 [33600/60000 (56%)]\tLoss: 0.211712\t Accuracy:96.132%\n",
      "Epoch : 6 [35200/60000 (59%)]\tLoss: 0.011926\t Accuracy:96.143%\n",
      "Epoch : 6 [36800/60000 (61%)]\tLoss: 0.071312\t Accuracy:96.079%\n",
      "Epoch : 6 [38400/60000 (64%)]\tLoss: 0.011845\t Accuracy:96.097%\n",
      "Epoch : 6 [40000/60000 (67%)]\tLoss: 0.062473\t Accuracy:96.103%\n",
      "Epoch : 6 [41600/60000 (69%)]\tLoss: 0.006744\t Accuracy:96.111%\n",
      "Epoch : 6 [43200/60000 (72%)]\tLoss: 0.157871\t Accuracy:96.107%\n",
      "Epoch : 6 [44800/60000 (75%)]\tLoss: 0.576204\t Accuracy:96.068%\n",
      "Epoch : 6 [46400/60000 (77%)]\tLoss: 0.110186\t Accuracy:96.054%\n",
      "Epoch : 6 [48000/60000 (80%)]\tLoss: 0.233235\t Accuracy:96.061%\n",
      "Epoch : 6 [49600/60000 (83%)]\tLoss: 0.129135\t Accuracy:96.057%\n",
      "Epoch : 6 [51200/60000 (85%)]\tLoss: 0.075290\t Accuracy:96.081%\n",
      "Epoch : 6 [52800/60000 (88%)]\tLoss: 0.331086\t Accuracy:96.076%\n",
      "Epoch : 6 [54400/60000 (91%)]\tLoss: 0.005308\t Accuracy:96.096%\n",
      "Epoch : 6 [56000/60000 (93%)]\tLoss: 0.266501\t Accuracy:96.097%\n",
      "Epoch : 6 [57600/60000 (96%)]\tLoss: 0.020916\t Accuracy:96.127%\n",
      "Epoch : 6 [59200/60000 (99%)]\tLoss: 0.210902\t Accuracy:96.146%\n",
      "Epoch : 7 [0/60000 (0%)]\tLoss: 0.061480\t Accuracy:96.875%\n",
      "Epoch : 7 [1600/60000 (3%)]\tLoss: 0.019263\t Accuracy:95.343%\n",
      "Epoch : 7 [3200/60000 (5%)]\tLoss: 0.334870\t Accuracy:95.730%\n",
      "Epoch : 7 [4800/60000 (8%)]\tLoss: 0.245364\t Accuracy:95.861%\n",
      "Epoch : 7 [6400/60000 (11%)]\tLoss: 0.193589\t Accuracy:95.989%\n",
      "Epoch : 7 [8000/60000 (13%)]\tLoss: 0.437203\t Accuracy:96.078%\n",
      "Epoch : 7 [9600/60000 (16%)]\tLoss: 0.010795\t Accuracy:96.096%\n",
      "Epoch : 7 [11200/60000 (19%)]\tLoss: 0.083915\t Accuracy:96.118%\n",
      "Epoch : 7 [12800/60000 (21%)]\tLoss: 0.172633\t Accuracy:96.018%\n",
      "Epoch : 7 [14400/60000 (24%)]\tLoss: 0.161091\t Accuracy:95.981%\n",
      "Epoch : 7 [16000/60000 (27%)]\tLoss: 0.000988\t Accuracy:95.846%\n",
      "Epoch : 7 [17600/60000 (29%)]\tLoss: 0.284908\t Accuracy:95.752%\n",
      "Epoch : 7 [19200/60000 (32%)]\tLoss: 0.248368\t Accuracy:95.762%\n",
      "Epoch : 7 [20800/60000 (35%)]\tLoss: 0.034281\t Accuracy:95.742%\n",
      "Epoch : 7 [22400/60000 (37%)]\tLoss: 0.213899\t Accuracy:95.774%\n",
      "Epoch : 7 [24000/60000 (40%)]\tLoss: 0.075230\t Accuracy:95.756%\n",
      "Epoch : 7 [25600/60000 (43%)]\tLoss: 0.032492\t Accuracy:95.829%\n",
      "Epoch : 7 [27200/60000 (45%)]\tLoss: 0.104426\t Accuracy:95.873%\n",
      "Epoch : 7 [28800/60000 (48%)]\tLoss: 0.225437\t Accuracy:95.914%\n",
      "Epoch : 7 [30400/60000 (51%)]\tLoss: 0.019082\t Accuracy:95.938%\n",
      "Epoch : 7 [32000/60000 (53%)]\tLoss: 0.216076\t Accuracy:95.942%\n",
      "Epoch : 7 [33600/60000 (56%)]\tLoss: 0.083289\t Accuracy:95.950%\n",
      "Epoch : 7 [35200/60000 (59%)]\tLoss: 0.069838\t Accuracy:95.955%\n",
      "Epoch : 7 [36800/60000 (61%)]\tLoss: 0.171479\t Accuracy:95.917%\n",
      "Epoch : 7 [38400/60000 (64%)]\tLoss: 0.054890\t Accuracy:95.959%\n",
      "Epoch : 7 [40000/60000 (67%)]\tLoss: 0.068655\t Accuracy:96.011%\n",
      "Epoch : 7 [41600/60000 (69%)]\tLoss: 0.019768\t Accuracy:96.027%\n",
      "Epoch : 7 [43200/60000 (72%)]\tLoss: 0.080216\t Accuracy:96.045%\n",
      "Epoch : 7 [44800/60000 (75%)]\tLoss: 0.026853\t Accuracy:96.061%\n",
      "Epoch : 7 [46400/60000 (77%)]\tLoss: 0.008326\t Accuracy:96.091%\n",
      "Epoch : 7 [48000/60000 (80%)]\tLoss: 0.832598\t Accuracy:96.103%\n",
      "Epoch : 7 [49600/60000 (83%)]\tLoss: 0.220904\t Accuracy:96.115%\n",
      "Epoch : 7 [51200/60000 (85%)]\tLoss: 0.080622\t Accuracy:96.141%\n",
      "Epoch : 7 [52800/60000 (88%)]\tLoss: 0.237872\t Accuracy:96.108%\n",
      "Epoch : 7 [54400/60000 (91%)]\tLoss: 0.181511\t Accuracy:96.105%\n",
      "Epoch : 7 [56000/60000 (93%)]\tLoss: 0.138647\t Accuracy:96.120%\n",
      "Epoch : 7 [57600/60000 (96%)]\tLoss: 0.059002\t Accuracy:96.146%\n",
      "Epoch : 7 [59200/60000 (99%)]\tLoss: 0.013986\t Accuracy:96.186%\n",
      "Epoch : 8 [0/60000 (0%)]\tLoss: 0.075311\t Accuracy:96.875%\n",
      "Epoch : 8 [1600/60000 (3%)]\tLoss: 0.041370\t Accuracy:95.650%\n",
      "Epoch : 8 [3200/60000 (5%)]\tLoss: 0.217862\t Accuracy:95.792%\n",
      "Epoch : 8 [4800/60000 (8%)]\tLoss: 0.196455\t Accuracy:95.737%\n",
      "Epoch : 8 [6400/60000 (11%)]\tLoss: 0.187682\t Accuracy:95.647%\n",
      "Epoch : 8 [8000/60000 (13%)]\tLoss: 0.211964\t Accuracy:95.867%\n",
      "Epoch : 8 [9600/60000 (16%)]\tLoss: 0.077093\t Accuracy:95.972%\n",
      "Epoch : 8 [11200/60000 (19%)]\tLoss: 0.235317\t Accuracy:96.056%\n",
      "Epoch : 8 [12800/60000 (21%)]\tLoss: 0.246036\t Accuracy:96.026%\n",
      "Epoch : 8 [14400/60000 (24%)]\tLoss: 0.027324\t Accuracy:95.981%\n",
      "Epoch : 8 [16000/60000 (27%)]\tLoss: 0.043377\t Accuracy:95.989%\n",
      "Epoch : 8 [17600/60000 (29%)]\tLoss: 0.192349\t Accuracy:95.973%\n",
      "Epoch : 8 [19200/60000 (32%)]\tLoss: 0.080711\t Accuracy:95.986%\n",
      "Epoch : 8 [20800/60000 (35%)]\tLoss: 0.248773\t Accuracy:95.987%\n",
      "Epoch : 8 [22400/60000 (37%)]\tLoss: 0.057428\t Accuracy:95.997%\n",
      "Epoch : 8 [24000/60000 (40%)]\tLoss: 0.280296\t Accuracy:96.059%\n",
      "Epoch : 8 [25600/60000 (43%)]\tLoss: 0.031392\t Accuracy:96.110%\n",
      "Epoch : 8 [27200/60000 (45%)]\tLoss: 0.078499\t Accuracy:96.155%\n",
      "Epoch : 8 [28800/60000 (48%)]\tLoss: 0.078537\t Accuracy:96.178%\n",
      "Epoch : 8 [30400/60000 (51%)]\tLoss: 0.054988\t Accuracy:96.205%\n",
      "Epoch : 8 [32000/60000 (53%)]\tLoss: 0.111466\t Accuracy:96.210%\n",
      "Epoch : 8 [33600/60000 (56%)]\tLoss: 0.365906\t Accuracy:96.200%\n",
      "Epoch : 8 [35200/60000 (59%)]\tLoss: 0.023364\t Accuracy:96.217%\n",
      "Epoch : 8 [36800/60000 (61%)]\tLoss: 0.060438\t Accuracy:96.199%\n",
      "Epoch : 8 [38400/60000 (64%)]\tLoss: 0.355091\t Accuracy:96.227%\n",
      "Epoch : 8 [40000/60000 (67%)]\tLoss: 0.023585\t Accuracy:96.223%\n",
      "Epoch : 8 [41600/60000 (69%)]\tLoss: 0.068775\t Accuracy:96.231%\n",
      "Epoch : 8 [43200/60000 (72%)]\tLoss: 0.032041\t Accuracy:96.232%\n",
      "Epoch : 8 [44800/60000 (75%)]\tLoss: 0.047113\t Accuracy:96.192%\n",
      "Epoch : 8 [46400/60000 (77%)]\tLoss: 0.018228\t Accuracy:96.210%\n",
      "Epoch : 8 [48000/60000 (80%)]\tLoss: 0.320751\t Accuracy:96.219%\n",
      "Epoch : 8 [49600/60000 (83%)]\tLoss: 0.156522\t Accuracy:96.232%\n",
      "Epoch : 8 [51200/60000 (85%)]\tLoss: 0.051963\t Accuracy:96.246%\n",
      "Epoch : 8 [52800/60000 (88%)]\tLoss: 0.411227\t Accuracy:96.235%\n",
      "Epoch : 8 [54400/60000 (91%)]\tLoss: 0.024031\t Accuracy:96.228%\n",
      "Epoch : 8 [56000/60000 (93%)]\tLoss: 0.023002\t Accuracy:96.245%\n",
      "Epoch : 8 [57600/60000 (96%)]\tLoss: 0.057057\t Accuracy:96.262%\n",
      "Epoch : 8 [59200/60000 (99%)]\tLoss: 0.068227\t Accuracy:96.259%\n",
      "Epoch : 9 [0/60000 (0%)]\tLoss: 0.256395\t Accuracy:93.750%\n",
      "Epoch : 9 [1600/60000 (3%)]\tLoss: 0.047816\t Accuracy:95.466%\n",
      "Epoch : 9 [3200/60000 (5%)]\tLoss: 0.342104\t Accuracy:95.854%\n",
      "Epoch : 9 [4800/60000 (8%)]\tLoss: 0.031443\t Accuracy:96.233%\n",
      "Epoch : 9 [6400/60000 (11%)]\tLoss: 0.076348\t Accuracy:96.300%\n",
      "Epoch : 9 [8000/60000 (13%)]\tLoss: 0.207400\t Accuracy:96.365%\n",
      "Epoch : 9 [9600/60000 (16%)]\tLoss: 0.003616\t Accuracy:96.169%\n",
      "Epoch : 9 [11200/60000 (19%)]\tLoss: 0.061793\t Accuracy:96.198%\n",
      "Epoch : 9 [12800/60000 (21%)]\tLoss: 0.225619\t Accuracy:96.205%\n",
      "Epoch : 9 [14400/60000 (24%)]\tLoss: 0.031612\t Accuracy:96.251%\n",
      "Epoch : 9 [16000/60000 (27%)]\tLoss: 0.041638\t Accuracy:96.239%\n",
      "Epoch : 9 [17600/60000 (29%)]\tLoss: 0.023064\t Accuracy:96.155%\n",
      "Epoch : 9 [19200/60000 (32%)]\tLoss: 0.518605\t Accuracy:96.111%\n",
      "Epoch : 9 [20800/60000 (35%)]\tLoss: 0.011192\t Accuracy:96.155%\n",
      "Epoch : 9 [22400/60000 (37%)]\tLoss: 0.121900\t Accuracy:96.224%\n",
      "Epoch : 9 [24000/60000 (40%)]\tLoss: 0.069339\t Accuracy:96.267%\n",
      "Epoch : 9 [25600/60000 (43%)]\tLoss: 0.075857\t Accuracy:96.301%\n",
      "Epoch : 9 [27200/60000 (45%)]\tLoss: 0.229748\t Accuracy:96.295%\n",
      "Epoch : 9 [28800/60000 (48%)]\tLoss: 0.259524\t Accuracy:96.320%\n",
      "Epoch : 9 [30400/60000 (51%)]\tLoss: 0.066590\t Accuracy:96.336%\n",
      "Epoch : 9 [32000/60000 (53%)]\tLoss: 0.114058\t Accuracy:96.316%\n",
      "Epoch : 9 [33600/60000 (56%)]\tLoss: 0.191098\t Accuracy:96.334%\n",
      "Epoch : 9 [35200/60000 (59%)]\tLoss: 0.083217\t Accuracy:96.327%\n",
      "Epoch : 9 [36800/60000 (61%)]\tLoss: 0.017521\t Accuracy:96.310%\n",
      "Epoch : 9 [38400/60000 (64%)]\tLoss: 0.045571\t Accuracy:96.308%\n",
      "Epoch : 9 [40000/60000 (67%)]\tLoss: 0.007678\t Accuracy:96.318%\n",
      "Epoch : 9 [41600/60000 (69%)]\tLoss: 0.234108\t Accuracy:96.323%\n",
      "Epoch : 9 [43200/60000 (72%)]\tLoss: 0.098674\t Accuracy:96.359%\n",
      "Epoch : 9 [44800/60000 (75%)]\tLoss: 0.048034\t Accuracy:96.353%\n",
      "Epoch : 9 [46400/60000 (77%)]\tLoss: 0.235049\t Accuracy:96.375%\n",
      "Epoch : 9 [48000/60000 (80%)]\tLoss: 0.300102\t Accuracy:96.350%\n",
      "Epoch : 9 [49600/60000 (83%)]\tLoss: 0.043877\t Accuracy:96.361%\n",
      "Epoch : 9 [51200/60000 (85%)]\tLoss: 0.016004\t Accuracy:96.369%\n",
      "Epoch : 9 [52800/60000 (88%)]\tLoss: 0.130954\t Accuracy:96.347%\n",
      "Epoch : 9 [54400/60000 (91%)]\tLoss: 0.121049\t Accuracy:96.337%\n",
      "Epoch : 9 [56000/60000 (93%)]\tLoss: 0.075730\t Accuracy:96.329%\n",
      "Epoch : 9 [57600/60000 (96%)]\tLoss: 0.179759\t Accuracy:96.353%\n",
      "Epoch : 9 [59200/60000 (99%)]\tLoss: 0.059943\t Accuracy:96.358%\n",
      "Test accuracy:0.985% \n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "evaluate(cnn)\n",
    "fit(cnn, loader_train)\n",
    "cnn.eval()\n",
    "evaluate(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 번째 학습데이터의 테스트 결과 : tensor([[-2.1293e+01, -5.9605e-07, -1.6726e+01, -2.5848e+01, -1.5562e+01,\n",
      "         -1.8650e+01, -1.8114e+01, -1.8724e+01, -1.4555e+01, -1.8872e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "10 번째 데이터의 예측 : [1]\n",
      "10 번째 데이터의 실제값 : 1\n"
     ]
    }
   ],
   "source": [
    "index = 10\n",
    "data = X_test[index].view(-1, 1, 28, 28).float()\n",
    "output = cnn(data)\n",
    "print('{} 번째 학습데이터의 테스트 결과 : {}'.format(index, output))\n",
    "_, predict = torch.max(output, 1)\n",
    "print('{} 번째 데이터의 예측 : {}'.format(index, predict.numpy()))\n",
    "print('{} 번째 데이터의 실제값 : {}'.format(index, y_test[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
